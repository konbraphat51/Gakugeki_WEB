{"ast":null,"code":"import _regeneratorRuntime from \"C:/Users/brigh/storage/js_project/Gakugeki_WEB/node_modules/@babel/runtime/helpers/esm/regeneratorRuntime.js\";\nimport _asyncToGenerator from \"C:/Users/brigh/storage/js_project/Gakugeki_WEB/node_modules/@babel/runtime/helpers/esm/asyncToGenerator.js\";\nimport { isOwnedByContext } from '../helpers/is-owned-by-context';\nexport var createAnalyserNodeRendererFactory = function createAnalyserNodeRendererFactory(createNativeAnalyserNode, getNativeAudioNode, renderInputsOfAudioNode) {\n  return function () {\n    var renderedNativeAnalyserNodes = new WeakMap();\n\n    var createAnalyserNode = /*#__PURE__*/function () {\n      var _ref = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee(proxy, nativeOfflineAudioContext) {\n        var nativeAnalyserNode, nativeAnalyserNodeIsOwnedByContext, options;\n        return _regeneratorRuntime().wrap(function _callee$(_context) {\n          while (1) {\n            switch (_context.prev = _context.next) {\n              case 0:\n                nativeAnalyserNode = getNativeAudioNode(proxy); // If the initially used nativeAnalyserNode was not constructed on the same OfflineAudioContext it needs to be created again.\n\n                nativeAnalyserNodeIsOwnedByContext = isOwnedByContext(nativeAnalyserNode, nativeOfflineAudioContext);\n\n                if (!nativeAnalyserNodeIsOwnedByContext) {\n                  options = {\n                    channelCount: nativeAnalyserNode.channelCount,\n                    channelCountMode: nativeAnalyserNode.channelCountMode,\n                    channelInterpretation: nativeAnalyserNode.channelInterpretation,\n                    fftSize: nativeAnalyserNode.fftSize,\n                    maxDecibels: nativeAnalyserNode.maxDecibels,\n                    minDecibels: nativeAnalyserNode.minDecibels,\n                    smoothingTimeConstant: nativeAnalyserNode.smoothingTimeConstant\n                  };\n                  nativeAnalyserNode = createNativeAnalyserNode(nativeOfflineAudioContext, options);\n                }\n\n                renderedNativeAnalyserNodes.set(nativeOfflineAudioContext, nativeAnalyserNode);\n                _context.next = 6;\n                return renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeAnalyserNode);\n\n              case 6:\n                return _context.abrupt(\"return\", nativeAnalyserNode);\n\n              case 7:\n              case \"end\":\n                return _context.stop();\n            }\n          }\n        }, _callee);\n      }));\n\n      return function createAnalyserNode(_x, _x2) {\n        return _ref.apply(this, arguments);\n      };\n    }();\n\n    return {\n      render: function render(proxy, nativeOfflineAudioContext) {\n        var renderedNativeAnalyserNode = renderedNativeAnalyserNodes.get(nativeOfflineAudioContext);\n\n        if (renderedNativeAnalyserNode !== undefined) {\n          return Promise.resolve(renderedNativeAnalyserNode);\n        }\n\n        return createAnalyserNode(proxy, nativeOfflineAudioContext);\n      }\n    };\n  };\n};","map":{"version":3,"mappings":";;AAAA,SAASA,gBAAT,QAAiC,gCAAjC;AAIA,OAAO,IAAMC,iCAAiC,GAAwC,SAAzEA,iCAAyE,CAClFC,wBADkF,EAElFC,kBAFkF,EAGlFC,uBAHkF,EAIlF;EACA,OAAO,YAAmE;IACtE,IAAMC,2BAA2B,GAAG,IAAIC,OAAJ,EAApC;;IAEA,IAAMC,kBAAkB;MAAA,sEAAG,iBAAOC,KAAP,EAAgCC,yBAAhC;QAAA;QAAA;UAAA;YAAA;cAAA;gBACnBC,kBADmB,GACEP,kBAAkB,CAAyBK,KAAzB,CADpB,EAGvB;;gBACMG,kCAJiB,GAIoBX,gBAAgB,CAACU,kBAAD,EAAqBD,yBAArB,CAJpC;;gBAMvB,IAAI,CAACE,kCAAL,EAAyC;kBAC/BC,OAD+B,GACrB;oBACZC,YAAY,EAAEH,kBAAkB,CAACG,YADrB;oBAEZC,gBAAgB,EAAEJ,kBAAkB,CAACI,gBAFzB;oBAGZC,qBAAqB,EAAEL,kBAAkB,CAACK,qBAH9B;oBAIZC,OAAO,EAAEN,kBAAkB,CAACM,OAJhB;oBAKZC,WAAW,EAAEP,kBAAkB,CAACO,WALpB;oBAMZC,WAAW,EAAER,kBAAkB,CAACQ,WANpB;oBAOZC,qBAAqB,EAAET,kBAAkB,CAACS;kBAP9B,CADqB;kBAWrCT,kBAAkB,GAAGR,wBAAwB,CAACO,yBAAD,EAA4BG,OAA5B,CAA7C;gBACH;;gBAEDP,2BAA2B,CAACe,GAA5B,CAAgCX,yBAAhC,EAA2DC,kBAA3D;gBApBuB;gBAAA,OAsBjBN,uBAAuB,CAACI,KAAD,EAAQC,yBAAR,EAAmCC,kBAAnC,CAtBN;;cAAA;gBAAA,iCAwBhBA,kBAxBgB;;cAAA;cAAA;gBAAA;YAAA;UAAA;QAAA;MAAA,CAAH;;MAAA,gBAAlBH,kBAAkB;QAAA;MAAA;IAAA,GAAxB;;IA2BA,OAAO;MACHc,MADG,kBACIb,KADJ,EAC6BC,yBAD7B,EACkF;QACjF,IAAMa,0BAA0B,GAAGjB,2BAA2B,CAACkB,GAA5B,CAAgCd,yBAAhC,CAAnC;;QAEA,IAAIa,0BAA0B,KAAKE,SAAnC,EAA8C;UAC1C,OAAOC,OAAO,CAACC,OAAR,CAAgBJ,0BAAhB,CAAP;QACH;;QAED,OAAOf,kBAAkB,CAACC,KAAD,EAAQC,yBAAR,CAAzB;MACH;IATE,CAAP;EAWH,CAzCD;AA0CH,CA/CM","names":["isOwnedByContext","createAnalyserNodeRendererFactory","createNativeAnalyserNode","getNativeAudioNode","renderInputsOfAudioNode","renderedNativeAnalyserNodes","WeakMap","createAnalyserNode","proxy","nativeOfflineAudioContext","nativeAnalyserNode","nativeAnalyserNodeIsOwnedByContext","options","channelCount","channelCountMode","channelInterpretation","fftSize","maxDecibels","minDecibels","smoothingTimeConstant","set","render","renderedNativeAnalyserNode","get","undefined","Promise","resolve"],"sources":["C:\\Users\\brigh\\storage\\js_project\\Gakugeki_WEB\\node_modules\\standardized-audio-context\\src\\factories\\analyser-node-renderer-factory.ts"],"sourcesContent":["import { isOwnedByContext } from '../helpers/is-owned-by-context';\nimport { IAnalyserNode, IMinimalOfflineAudioContext, IOfflineAudioContext } from '../interfaces';\nimport { TAnalyserNodeRendererFactoryFactory, TNativeAnalyserNode, TNativeOfflineAudioContext } from '../types';\n\nexport const createAnalyserNodeRendererFactory: TAnalyserNodeRendererFactoryFactory = (\n    createNativeAnalyserNode,\n    getNativeAudioNode,\n    renderInputsOfAudioNode\n) => {\n    return <T extends IMinimalOfflineAudioContext | IOfflineAudioContext>() => {\n        const renderedNativeAnalyserNodes = new WeakMap<TNativeOfflineAudioContext, TNativeAnalyserNode>();\n\n        const createAnalyserNode = async (proxy: IAnalyserNode<T>, nativeOfflineAudioContext: TNativeOfflineAudioContext) => {\n            let nativeAnalyserNode = getNativeAudioNode<T, TNativeAnalyserNode>(proxy);\n\n            // If the initially used nativeAnalyserNode was not constructed on the same OfflineAudioContext it needs to be created again.\n            const nativeAnalyserNodeIsOwnedByContext = isOwnedByContext(nativeAnalyserNode, nativeOfflineAudioContext);\n\n            if (!nativeAnalyserNodeIsOwnedByContext) {\n                const options = {\n                    channelCount: nativeAnalyserNode.channelCount,\n                    channelCountMode: nativeAnalyserNode.channelCountMode,\n                    channelInterpretation: nativeAnalyserNode.channelInterpretation,\n                    fftSize: nativeAnalyserNode.fftSize,\n                    maxDecibels: nativeAnalyserNode.maxDecibels,\n                    minDecibels: nativeAnalyserNode.minDecibels,\n                    smoothingTimeConstant: nativeAnalyserNode.smoothingTimeConstant\n                };\n\n                nativeAnalyserNode = createNativeAnalyserNode(nativeOfflineAudioContext, options);\n            }\n\n            renderedNativeAnalyserNodes.set(nativeOfflineAudioContext, nativeAnalyserNode);\n\n            await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeAnalyserNode);\n\n            return nativeAnalyserNode;\n        };\n\n        return {\n            render(proxy: IAnalyserNode<T>, nativeOfflineAudioContext: TNativeOfflineAudioContext): Promise<TNativeAnalyserNode> {\n                const renderedNativeAnalyserNode = renderedNativeAnalyserNodes.get(nativeOfflineAudioContext);\n\n                if (renderedNativeAnalyserNode !== undefined) {\n                    return Promise.resolve(renderedNativeAnalyserNode);\n                }\n\n                return createAnalyserNode(proxy, nativeOfflineAudioContext);\n            }\n        };\n    };\n};\n"]},"metadata":{},"sourceType":"module"}